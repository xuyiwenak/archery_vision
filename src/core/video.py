import os
import cv2

from src.core.log import logger, log_process


class Video:
    def __init__(self, input_path, output_path) -> None:
        self.input_path = input_path
        self.output_path = output_path
         # è§†é¢‘è¾“å…¥
        self.capture = cv2.VideoCapture(input_path)
        # è§†é¢‘å±æ€§
        self.total_frames = int(self.capture.get(cv2.CAP_PROP_FRAME_COUNT))
        self.fps = int(self.capture.get(cv2.CAP_PROP_FPS))
        self.frame_size = (int(self.capture.get(3)), int(self.capture.get(4)))
        logger.info(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {self.total_frames}å¸§ | {self.fps}FPS | å°ºå¯¸ {self.frame_size}")
        # è§†é¢‘è¾“å‡º
        self.writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'avc1'), self.fps, self.frame_size)
        self.processed = 0

    def close(self):
        self.capture.release()
        self.writer.release()

    @staticmethod
    def extract_frame(video_path, frame_number):
        """ä»è§†é¢‘ä¸­æå–æŒ‡å®šå¸§å·çš„å›¾åƒ"""
        if not video_path or not os.path.exists(video_path):
            return None

        try:
            cap = cv2.VideoCapture(video_path)
            # è®¾ç½®å¸§ä½ç½®
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            # è¯»å–æŒ‡å®šå¸§
            success, frame = cap.read()
            cap.release()
            
            if success:
                # å°†BGRæ ¼å¼è½¬æ¢ä¸ºRGBæ ¼å¼
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                return frame_rgb
            else:
                print(f"æ— æ³•è¯»å–å¸§ {frame_number}")
                return None
        except Exception as e:
            print(f"æå–å¸§æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return None

    @log_process
    def process_frames_batch(self, model, batch_size):
        """æ‰¹é‡å¤„ç†è§†é¢‘å¸§
        Args:
            model: YOLOæ¨¡å‹å®ä¾‹
            batch_size: æ‰¹å¤„ç†å¤§å°
        Yields:
            tuple: (frame, result) åŸå§‹å¸§å’ŒYOLOå¤„ç†ç»“æœ
        """
        frame_buffer = []
        while self.capture.isOpened():
            success, frame = self.capture.read()
            if not success: 
                if frame_buffer:
                    results = model.track(frame_buffer, imgsz=320, conf=0.5, verbose=False, stream=True)
                    for k, result in enumerate(results):
                        yield frame_buffer[k], result
                break
            frame_buffer.append(frame)
            if len(frame_buffer) == batch_size:
                results = model.track(frame_buffer, imgsz=320, conf=0.5, verbose=False, stream=True)
                for k, result in enumerate(results):
                    yield frame_buffer[k], result
                frame_buffer = []

    def write_frame(self, frame):
        """å†™å…¥å¤„ç†åçš„å¸§åˆ°è¾“å‡ºè§†é¢‘
        Args:
            frame: å¤„ç†åçš„å¸§
        """
        self.processed += 1
        self.writer.write(frame)

    @staticmethod
    def draw_texts(frame, texts):
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ–‡æœ¬ä¿¡æ¯
        Args:
            frame: è§†é¢‘å¸§
            texts: è¦ç»˜åˆ¶çš„æ–‡æœ¬åˆ—è¡¨
        Returns:
            frame: ç»˜åˆ¶åçš„å¸§
        """
        for k, text in enumerate(texts):
            cv2.putText(frame, text, (50, (k + 1) * 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        return frame